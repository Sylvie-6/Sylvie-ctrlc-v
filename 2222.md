数据集	
- 训练集：NISQA 语料库，过滤后得到 **9537 样本（2216名说话人）**用于训练，**2237 样本（426名说话人）**用于验证，采样率 48 kHz。
- 测试集：包含两个部分：① NISQA 英语测试集（120 个样本）；② 作者自建的 Mandarin + Online Meeting 测试集（含匹配参考 MR 和不匹配参考 NMR 两种任务，每类 120 样本，涵盖噪声、丢包、非线性处理、低音量等失真类型）。

是否涉及编码器损伤	提及的失真类型主要包括 背景噪声、丢包、非线性处理、低音量，但未明确涉及“编解码压缩损伤”。重点在于 真实通信场景的退化音频。

标签工具与方法	主观 MOS 标签：遵循 ITU-T P.808 进行众包式测试；在部分测试中使用 MUSHRA (ITU-R BS.1534) 标准以降低主观偏差。

特征输入	
- 从失真语音提取 Mel-spectrogram 特征；
- 同时引入 说话人嵌入（Speaker Embedding）（由 U-Net 自注意力模型训练提取，或 ECAPA-TDNN 对照）作为先验信息输入 MOS 预测网络。

模型结构	
- 基于 自注意力 (Self-Attention) 的 MOS 预测网络；
- 说话人嵌入通过独立管道提取，并与 MOS 模型隐藏层向量拼接；
- 引入 Cosine Similarity Loss + MOS 损失 联合训练，以优化嵌入与 MOS 的一致性；
- 低复杂度，推理仅需 CPU 1.5% 实时因子。

模型输出及误差	
输出为预测的 MOS 分数 (1–5)。
- MR (匹配参考) 任务：PCC = 0.92，RMSE = 0.45；
- NMR (不匹配参考) 任务：依旧保持领先表现，显著优于对比方法（如 DNSMOS、NISQA、POLQA 等）。

引用数	论文发表于 IEEE Signal Processing Letters (2024, Vol.31)，DOI: 10.1109/LSP.2024.3478211。目前为最新论文，预计引用数接近 0–若干。

---
数据集	使用 Free Music Archive (FMA) 数据集，具体为 fma-small 子集，包含 8,000 样本，44.1kHz 采样率，每段 30s。作者将其切分为 10s 片段，并在其上加入失真（噪声、静态、混响、压缩、丢包、滤波等）。训练/验证/微调/测试划分比例为 25:5:1:1。

是否涉及编码器损伤	是的，论文在模拟失真时引入了 编解码压缩损伤，使用 Opus 和 AVS2-P3 编码器，不同码率下生成压缩失真样本。

标签工具与方法	两阶段：
1. 预训练阶段：使用客观指标作为标签，包括 PEAQ、VISQOL、Si-SNR、WSS、LLR。
2. 微调阶段：使用 主观 MOS 标签（由 36 名听音者评分，每段 ≥4 个评分，取平均值）。

特征输入	Mel-spectrogram + Constant-Q Transform (CQT) 作为双通道输入（每个帧长 1024，hop size 512，112 维特征），拼接后送入网络。

模型结构	
- 六层 Gated Convolution (GConv2d)，多尺度卷积提取特征
- 双向 GRU (BiGRU) ×4：前两层做时序建模，后两层双路并行处理“score/distance”指标
- FC-Attention 层：区分指标类别
- 全连接层 (Dense blocks) 输出 MOS。
  
模型输出及误差	输出为预测的 MOS 分数 (1–5)。\
最终结果（带所有模块）：MSE = 0.230, RMSE = 0.480, PLCC = 0.920, SROCC = 0.892。对比传统方法（PEAQ、POLQA、VISQOL），误差更低、相关性更高。

引用数	论文发表于 2024 ISCSLP (International Symposium on Chinese Spoken Language Processing)。目前是 IEEE Xplore 收录论文，由于较新（2024 年），引用数暂时可能接近 0–数个。
