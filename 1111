1. 论文做了什么（一眼看懂）

任务：无参考（non-intrusive）下，对失真音频直接回归 MOS (1–5)。输入只要失真音频，不要干净参考。

特征：把 Mel 频谱与 CQT 拼成双通道输入（高采样率音频里，CQT能补充对音乐音高/谐波的刻画，Mel更贴近听觉感知）。帧长 1024、hop 512、频带维度 112。

网络：前端 6 个 GConv2d 门控卷积块抽特征 → 2 层 BiGRU整合时序 → 双路径 BiGRU分别对“分数类指标（score）”与“距离类指标（distance）”做子任务学习 → Dense 头；再在双路径后加一个 FC-attention 轻量注意力。

两步训练：

Step-1 预训练：用客观指标做标签（score: PEAQ、VISQOL；distance: SI-SNR、WSS、LLR），并给 distance 指标配上 EdgeLoss；

Step-2 微调：再用主观 MOS做标签，端到端对齐人耳感知。

结果：全模块打开时 MSE=0.230，RMSE=0.480，PLCC=0.920，SROCC=0.892，显著优于 PEAQ/POLQA/VISQOL（分数映射到 1–5 后对比）。消融显示：GConv2d、FC-attention、两步训练、混合特征（Mel+CQT）都带来增益。

2. 数据与失真模拟（含“丢包/掉帧”）

数据：FMA-small（8,000 段、8 个流派、44.1 kHz，每段 30 s），先过滤低质样本，再切 10 s 片段并划分：预训练/微调/验证/测试 ≈ 25/5/1/1。微调/验证/测试由受试者给出 MOS（每段≥4 人，取均值）。

六类退化：噪声（多 SNR）、静态失真（帧级增益跳变）、混响（pyroomacoustics，变房间/RT60）、编码压缩（Opus、AVS2-P3，多码率）、dropout 掉帧/丢包（Gilbert-Elliot 模型生成帧级 mask，模拟突发与随机丢包）、滤波（高/低通不同截止频）。这一点很贴近你 VoIP 的关心点：论文里明确模拟了丢包，但丢包不是作为网络输入特征，而是用于生成退化音频。

3. 特征与输入张量

双通道输入：

通道1：Mel-spectrogram（112 维带）

通道2：CQT（112 维带）
两者按时间对齐后在“通道维”拼接，进入 2D 卷积前端；设置帧长 1024、hop 512以兼顾高采样率音频的时频分辨率。

4. 网络结构（逐层拆解）

(1) 前端：6× GConv2d（门控卷积）

每个 GConv2d 块 = 主卷积支路（Conv2d+BN+Dropout） × 门控支路（Conv2d+Sigmoid），输出是两支路的逐点乘积（让网络自动“抑制不重要区域，强调关键信号”）。卷积核尺寸逐层变化（多尺度感受野）。示意如图 2。

通道与核/步长（摘自 Table 1）：

2→16, k=(3×3), stride (1,2)

16→32, k=(3×5), s (1,2)

32→64, k=(3×5), s (1,3)

64→128, k=(3×5), s (1,1)

128→256, k=(3×3), s (1,1)

256→512, k=(3×1), s (1,1)
通过在“时间维”逐步下采样（如 stride 的 2/3），压缩序列长度，保留时频关键纹理。

(2) 时序整合：2× BiGRU

在卷积后接两层 BiGRU，融合前后文依赖（音频质量的感知有显著的时间上下文）。

(3) 双路径子任务：score vs. distance

再接两条平行 BiGRU：

score 支路回归PEAQ、VISQOL（这类“分数型”客观指标）

distance 支路回归 SI-SNR、WSS、LLR（“距离/相似度度量”类）

两支路后各接 Dense 头输出对应指标；在双路径之后再加一个轻量 FC-attention（文中叫 PC-attention），让网络区分两类指标的“关注点”并加权。

(4) MOS 头

预训练完成后，切到第二阶段，用主观 MOS做标签进行微调，最终输出单一的 MOS 预测（1–5 缩放域）。

5. 训练目标与 EdgeLoss

Step-1（预训练）：

score 指标（PEAQ、VISQOL）→ MSE；

distance 指标（SI-SNR、WSS、LLR）→ EdgeLoss：

直觉：这些度量的“数值间隔”不等价（越到极端区间，单位间隔代表的“感知差别”反而变小/对训练有害）。

做法：用带阈值 T与**权重 β(x,y)**的加权 L1/变体，超阈后惩罚增长速率降低，避免极端样本主导梯度。

总损失 = MSE(PEAQ)+MSE(VISQOL)+λ₁·Edge(SI-SNR)+λ₂·Edge(WSS)+λ₃·Edge(LLR)。文中示例：λ₁=0.001，λ₂=0.1，λ₃=0.001；WSS/LLR 的阈值 50/10，SI-SNR 用 ±30。

Step-2（微调）：MOS→MSE。

6. 训练细节（复现实用）

优化器/超参：Adam，lr=1e-4；Dropout=0.2；

批量/轮次：预训练 batch=128，最少 300 个 epoch，早停 patience=10；微调 batch=32，最少 100 个 epoch，早停 patience=10；使用 RTX 3090 训练。
